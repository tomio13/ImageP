#!/usr/bin/env python
#######################################################################
"""	ImageP.Convolve: some simple convolution based on numpy.FFT

    Author: Tamas Haraszti, Biophysical Chemistry group at the University of
            Heidelberg

    Copyright:	LGPL-3
    Warranty:	For any application, there is no warranty 8).
"""
from Kernels import *
from Display import display

from numpy import zeros, repeat, log, exp,  sqrt
from numpy import fft

from time import time
####################################################################
__all__=[  "BPass","ConvFilter","ConvFilter1D",\
        "MeanFilter", "GaussDeblurr", "GrayErode", "GrayDilate",\
        "DownsizeImage", "UpsizeImage", "RollingBall"]
            

#####################################################################

def ConvFilter(image1, image2, pad=True, MinPad=True, Smooth=False,\
        PadValue=0.0):
    """This is a Filter, to provide either smoothing or positioning 
       information from images by doing convolution between image1
       and image2. It deviates a bit from the standard math when 
       Smooth=False is used. 
    
       The scipy.signal.convolve2d function is very slow,
       the fftconvolve is pretty good.
       This one was a middle step, with reasonable speed
       between the two. fftconvolve is much faster for large*large
       images, but for moderated size the two are about the same speed.
       
       Here we do the filtering in Fourier space. 
        
        Then we take the F-transform, multiply, transform back and 
        return the real part of the result. This is still faster than
        the built in convolution (in the scipy package).

        (The algorithm does not change the type of the data)

        Input parameters:
        	image1, image2:		an image and a kernel
        pad:			padding to the next power of 2
        MinPad:			If MinPad is True, then the two 
                    images are padded to the 
                    size of the sum of the dimensions 
                    via zeros.
                    Else the larger size is doubled in
                    the padding (see Numerical Recipies
                    in C++, example).
        Smooth:			If True, then image2 is a kernel
                    else image2 is inverted, and 
                    image2[::-1,::-1] is used.
                    This results peaks related to 
                    how much image2 has to be shifted
                    to match the pattern in image1.
                    Let it be True for kernels, where
                    symmetry is not an issue.
        PadValue    use this to fill up the padding area, for the case
                    it is not 0.0

        return value:
        an image with the real part of the inverse FFT.
        If Smooth is set, then it supposed to be a smoothed image,
        else a real convolution.
    """

    r1,c1  = image1.shape
    r2,c2  = image2.shape

    #we need these FFTs:
    Fft = fft.fft2
    iFft = fft.ifft2

    #Padding to the end. Inserting to the middle would
    #break up the resulted image.
    #The window filled within:

    if MinPad:
        x1 = r1 + r2
        y1 = c1 + c2
    else :
        x1 = 2 * max(r1,r2)
        y1 = 2 * max(c1,c2)
    #end if MinPad

    xOrig = r1+r2
    yOrig = c1+c2

    #scale further up?
    if pad:
        lg2 = log(2)
        #round up to the next power of two:
        px2 = int(log(x1)/lg2 + 1.0)
        py2 = int(log(y1)/lg2 + 1.0)
        x1 = 2**px2
        y1 = 2**py2
#		x0 = int(x1 - xOrig)/2
#		y0 = int(y1 - yOrig)/2

    #To have a good result, we have to pad up the images:
    #These FFT functions take care of the normalization as well!
    #The convolution has a rotation effect, which can be circumvented
    #by rotating the image. If used for feature identification, rotate the
    #second image! [::-1,::-1]
    if Smooth:
        fftimage = Fft(image1, s=(x1,y1)) * Fft(image2,s=(x1,y1))
    else :
        fftimage = Fft(image1, s=(x1,y1)) * \
                Fft(image2[::-1,::-1],s=(x1,y1))
        
    #Conjugation would turn it to correlation:
    #fftimage = Fft(image1,s=(x1,y1)) * \
    #		Fft(image2, s=(x1,y1)).conjugate()*indx

    return ((iFft(fftimage))[:xOrig,:yOrig]).real
#end of ConvFilter

##############
def ConvFilter1D(image, kernel, pad=True, MinPad=True):
    """This is a Filter, to provide smoothing with kernels, which
        can be generated from 1D arrays (Gaussian, binomial, boxcar,
        etc.).
       Here we do the filtering in Fourier space. 
        
        Then we take the F-transform, multiply, transform back and 
        return the real part of the result. This is still faster than
        the built in convolution (in the scipy package).

        (The algorithm does not change the type of the data)

        Input parameters:
        image, kernel:		an image and a kernel (this latter is 1D)
        pad:			    padding to the next power of 2
        MinPad:			    If MinPad is True, then the two 
                            images are padded to the 
                            size of the sum of the dimensions 
                            via zeros.
                            Else the larger size is doubled in
                            the padding (see Numerical Recipies
                            in C++, example).

        return value:
        an image with the real part of the inverse FFT.
    """

    r1,c1  = image.shape
    ksize = kernel.shape[0]

    if image.ndim != 2 :
        print("this filter is meant for 2D images")
        return None
    #end if

    #we need these FFTs:
    Fft = fft.fft
    iFft = fft.ifft

    #Padding to the end. Inserting to the middle would
    #break up the resulted image.
    #The window filled within:

    if MinPad:
        x1 = r1 + ksize
        y1 = c1 + ksize
    else :
        x1 = 2 * max(r1, ksize)
        y1 = 2 * max(c1, ksize)

    XOrig = x1
    YOrig = y1
    #scale further up?
    if pad:
        lg2 = log(2)
        #round up to the next power of two:
        px2 = int(log(x1)/lg2 + 1.0)
        py2 = int(log(y1)/lg2 + 1.0)
        x1 = 2**px2
        y1 = 2**py2
    #end if pad
        
    #Now the job:
    resimg = zeros((XOrig, YOrig))

    #1. go along axis 1.
    fftkernel = Fft(kernel,y1)
    for i in xrange(image.shape[0]):
        fftline = Fft(image[i,:],y1) *fftkernel
        resimg[i,:] = iFft(fftline)[:YOrig].real
    #end for
    fftkernel = Fft(kernel,x1)
    for j in xrange(resimg.shape[1]):
        fftline = Fft(resimg[:,j],x1) * fftkernel
        resimg[:,j] = iFft(fftline)[:XOrig].real
    #end for
    #It should be fine now, padding is already taken off

    return resimg
#end ConvFilter1D


def MeanFilter(image,r=5):
    """Do a simple averaging along the image in order
       to smooth out intensity fluctiations.
       
       It will also increase the size of the image.
       
       r: the range or radius of work to do. 

       We do this by convolving the image with a Boxcar kernel of size r.
       To use it as a dilate algorithm, filter the image with a 
       treshold, then apply the filter. Then use a 0.2-0.8 treshold 
       again. The points which have enough neigbourhs will be turned to 1.
    """
    w = int(r/2)
    kernel = BoxcarKernel(w, norm=True, OneD=True)

    return ConvFilter1D(image,kernel)[w:-w-1,w:-w-1]
#End of Mean function

def BPass(img, lobject, lnoise, noclip = False, AutoStretch=False):
    """This is an implementation of the bandpass routine of Grier at al.
       (and perhaps a variant as well 8) )

       The function takes an image, generates a Gaussian and a Boxcar
       mask, takes the convolcution of image with the two masks and 
       returns the difference.

       Based on the paper of Crocker et al. Journal of Colloid and Interface
       Science, vol. 179, page 298-310 (1996).

       The Gaussian should enhance + smooth features, while the Boxcar
       should surpress noise.

       Parameters:
       lobject: length scale of the object
       lnoise:  length scale of the noise; related to the width of smoothing

       noclip: (True or False(default)) Do not clip the convolution edges
       AutoStretch: (True or False(defaut) to stretch the size of the window
       		(lobject) to keep it 2*lnoise size

       Return:
       	the modified image
    """
    b = float(lnoise)
    w = int(lobject)

    #If the noise overruns the object size, than that scale
    #should dominate:

    if AutoStretch and w < (2*b):
        w = 2*int(b)
    
    #Now the filtering:
    ## GaussKernel returns a 2*w+1 size matrix with the Gaussian filled in:
    #since our Gaussian is r^2/(2*width^2) and we want r^2/(4*b^2):
    g = GaussKernel(w, width=(sqrt(2.0)*b), norm=True, OneD=True)
    gi = ConvFilter1D(img,g)

    # BoxcarKernel returns a 2*w+1 size uniform array normalized to 1.
    # (filled up with 1/N)
    bb = BoxcarKernel(w, norm=True, OneD=True)
    bi = ConvFilter1D(img,bb)
    
    result = gi - bi
    
    if noclip:
        return result
    else :
        return result[w:-(w+1),w:-(w+1)]
#End of BPass()

def GaussDeblurr(img, r1=50, w1=25, r2=5, w2=2,\
        KillZero=False, verbose =False):
    """ Gaussian deblurr using Gauss(r1,w1)and smooth
        Such a deblurring filter is generally used in fluorescence
        microscopy to enhance contrast, as a quick and dirty approach
        instead of proper deconvolution.
        
        Make two Gaussian filters: 
        one with a size of 2*r1+1, the other with size 2*r2+1.
        Their std is w1 and w2 (width parameter in GaussKernel)

        Both filters are normalized, and the result is clipped to its
        original size.

        Generate blurred image using kernel1, and subtract it from the
        original image.

        shift the result to have minimum = 0. (subtract its minimum)

        Convolve the result with the smoothing, secong kernel and return
        the result.
        (Warning: if there is a structure at the edges, they mey get
        distorted by the deblurring...)

        Parameters:
         r1, r2:        the size for the Gauss kernel matrix (2*r+1)
                        if r2 < 1: no smoothing is done
         w1, w2:        width parameter for the kernels
         KillZero:      if True, keep nonnegative values after the
                        background subtraction
         verbose:       if True, display image

    """

    #oneD convolution is faster:
    if r1 < 1:
        print("invalid kernel size")
        return None
    if r1 < 10 or w1 < 10:
        print("Warning: small kernel of %d, %.2f" %((2*r1+1), w1))

    k1 = GaussKernel(r1,w1, norm=True, OneD= True)

    t0 = time() if verbose else 0.0
    img = img - img.min()
    img2 = ConvFilter1D(img, k1, pad=True)[r1:-r1-1,r1:-r1-1]

    if verbose:
        print("First convolution took %.3f seconds" %(time()-t0))

    #Subtracting blurr:
    img2 = img - img2

    if KillZero:
        img2[img2 <0] = 0
    else:
        img2 = img2 - img2.min()

    if r2 > 0:
        k2 = GaussKernel(r2,w2, norm=True, OneD= True)

        t0 = time() if verbose else 0.0
        img3 = ConvFilter1D(img2, k2, pad=True)[r2:-r2-1,r2:-r2-1]
        if verbose:
            print("Second convolution took %.3f seconds" %(time()-t0))

    else:
        if verbose:
            print("No smoothing (smoothing kernel is emtpy)")

        img3 = img2


    if verbose:
        display(img3, colorbar=False)

    return img3
#end of GaussDeblurr


def GrayErode(image, kernel, cutZero= True):
    """ Do a grayscale erosion with a kernel. This is quite like
        the Minkowski sum for the image and the kernel.

        Result is calculated as:
        min(image(x-i, y-j) - kernel(i,j)) for all i,j at
        every x,y

        if cutZero is set, then ignore the points where the
        kernel is 0
    """
    kNi, kNj = kernel.shape

    #some kernels are there for a shape
    #zero values should be ignored
    kindx = kernel != 0

    kNi2 = kNi/2
    kNj2 = kNj/2

    Ni, Nj = image.shape
    result = image.copy()

    #we do using a single loop
    for ii in range(Ni*Nj):
        i = int(ii/Nj)
        j = ii %Nj
        #pixels under the kernel:

        i0 = max(0, i- kNi2)
        j0 = max(0, j- kNj2)
        i1 = min(Ni, i+ kNi2 +1)
        j1 = min(Nj, j+ kNj2 +1)
        imgpart = image[ i0:i1, j0:j1]
            
        #i-i0 = kNi2 or less. If less, we have to cut
        #from the ball image:
        bi0 = kNi2 - (i - i0)
        bj0 = kNj2 - (j - j0)
        bi1 = kNi - (kNi2 + 1 - (i1 - i))
        bj1 = kNj - (kNj2 + 1 - (j1 - j))
        kpart = kernel[bi0:bi1, bj0:bj1]
        
        #the difference:
        diff = imgpart - kpart
        result[i,j] =  (diff[kindx[bi0:bi1,bj0:bj1]]).min() if cutZero\
                        else diff.min()
    #end for ii
    
    return result
#end GrayErode


def GrayDilate(image, kernel, cutZero= True):
    """ Do a grayscale dilation with a kernel. This is quite like
        the Minkowski sum for the image and the kernel.

        Result is calculated as:
        max(image(x-i, y-j) + kernel(i,j)) for all i,j at
        every x,y

        if cutZero is set, then ignore the points where the
        kernel is 0
    """
    kNi, kNj = kernel.shape

    #some kernels are there for a shape
    #zero values should be ignored
    kindx = kernel != 0
    
    kNi2 = kNi/2
    kNj2 = kNj/2

    Ni, Nj = image.shape
    result = image.copy()

    #we do using a single loop
    for ii in range(Ni*Nj):
        i = int(ii/Nj)
        j = ii %Nj
        #pixels under the kernel:

        i0 = max(0, i- kNi2)
        j0 = max(0, j- kNj2)
        i1 = min(Ni, i+ kNi2 +1)
        j1 = min(Nj, j+ kNj2 +1)
        imgpart = image[ i0:i1, j0:j1]
            
        #i-i0 = kNi2 or less. If less, we have to cut
        #from the ball image:
        bi0 = kNi2 - (i - i0)
        bj0 = kNj2 - (j - j0)
        bi1 = kNi - (kNi2 + 1 - (i1 - i))
        bj1 = kNj - (kNj2 + 1 - (j1 - j))
        kpart = kernel[bi0:bi1, bj0:bj1]
        
        #the difference:
        diff = imgpart + kpart
        result[i,j] =  (diff[kindx[bi0:bi1,bj0:bj1]]).max() if cutZero\
                        else diff.max()
    #end for ii
    
    return result
#end GrayErode


def DownsizeImage(image, rI, rJ = 0):
    """ Reduce an image in size by averaging pixels.
        
        The method is a simple mean function by rearranging
        the image pixels. Thus, if the image size can not be
        divided by rI or rJ, we have a problem.

        The routine truncates the image for such cases, so be
        careful and check before calling.

        image:  the image to be reduced
        rI, rJ: reduction factors along i and j indices
                if rJ < 1, then use rI instead

        return: reduced image
    """
    if rJ < 1:
        rJ = rI
    
    Ni, Nj = image.shape
    Ni = Ni - Ni%rI
    Nj = Nj - Nj%rJ

    a = image[:Ni,:Nj].copy()
    if rI > 1:
        rNi = Ni/rI
        a.shape = (rNi,rI,Nj)
        a = a.mean(axis=1)
    #end if rI

    if rJ > 1:
        rNj = Nj/rJ
        #turn it around, so we can do the same as for Ni:
        a = a.transpose()
        a.shape = (rNj,rJ, rNi)
        #calculate and turn the result back:
        a = a.mean(axis=1).transpose()
    #end if rJ  

    return a
#end DownsizeImage


def UpsizeImage(image, uI, uJ=0):
    """ Upsize the image using numpy.repeat.
        This will simply repeat the values of the image
        uI and uJ times.

        Parameters:
        image:      image to be upsized
        uI, uJ:     scaling factors to use
                    if uJ < 1 then uI = uJ

        return:
            upsized image
    """
    if uJ < 1:
        uJ = uI
    #end if
    Ni, Nj = image.shape

    if uI > 1:
        a = repeat(image, uI, axis=0)
    else:
        #we will need it for defining the end shape
        uI = 1
        a = image.copy()
    #end if uI

    if uJ > 1:
        a = repeat(a, uJ, axis=1)
    else:
        uJ = 1

    a.shape = (Ni*uI, Nj*uJ)
    return a
#end UpsizeImage

def RollingBall(image, r, reduce=4, verbose= False):
    """
        Rolling ball background calculation based on the java plugin
        written for ImageJ.

        Original source at:
        http://rsbweb.nih.gov/ij/developer/source/ij/plugin/filter/BackgroundSubtracter.java.html

        There is a variant at the github, which did not utilize the 
        capabilities of numpy. This one is a complete rewrite, utilizing
        the numpy.ndarray features.

        An alternative version would be using GrayErode and GrayDilate
        also on a downsized image.

        image:      the image to be processed
        r:          radius of the ball to be used
        reduce:     scale both the image and the ball with this factor
                    (use DownsizeImage and UpsizeImage)
        verbose     show the kernel

        return:     background image
    """
    if r < 2:
        print("Required a ball radius >1 for processing")
        raise ValueError
    if r < 2*reduce:
        print("Radius %.2f too small to reduce with %d" %(r, reduce))
        raise ValueError

    if reduce > 2:
        reduce = int(reduce)
        #r = reduce/2
        img = DownsizeImage(image, reduce)
        r = r/reduce
    else:
        img = image.copy()
    #end if reduce

    ball = BallKernel(r)
    if verbose:
        display(ball,1)

    #image parameters:
    Ni, Nj = img.shape

    #ball parameters:
    
    ball_width = ball.shape[0]
    radius = int((ball_width-1) / 2)
    #kill zero pixels from the comparison
    bindx = (ball > 0)

    result = zeros(img.shape, dtype="f")

    #where it the ball standing?
    zcontrol = img[0,0]

    #the ball image hangs off +/- radius
    #we have the ball at each pixel of the image
    #running only one loop instead of 2:
    for ii in range(Ni*Nj):
        i = int(ii/Nj)
        j = ii %Nj
        #now there are pixels under the ball, either hitting
        #the ball or not
        i0 = max(0, i-radius)
        j0 = max(0, j-radius)
        i1 = min(Ni, i+radius+1)
        j1 = min(Nj, j+radius+1)
        imgpart = img[ i0:i1, j0:j1]
            
        #i-i0 = radius or less. If less, we have to cut
        #from the ball image:
        bi0 = radius - (i - i0)
        bj0 = radius - (j - j0)
        bi1 = ball_width - (radius + 1 - (i1 - i))
        bj1 = ball_width - (radius + 1 - (j1 - j))
        ballpart = zcontrol + ball[bi0:bi1, bj0:bj1]
        
        #print(ballpart)
        #print(imgpart)
        #the difference:
        diff = imgpart - ballpart
        min_z = (diff[bindx[bi0:bi1, bj0:bj1]]).min()
        if min_z < 0:
            i0 = i
            bi0 = radius

        #this is not what the paper said...
        #but a copy of what the ImageJ plugin does:
        #move the ball up or down to have it on the surface:
        zcontrol = zcontrol + min_z
        #now find and override those pixels where the ball
        #is over them:
        ballpart = zcontrol + ball[bi0:bi1, bj0:bj1]
        result[i,j] = ballpart[bindx[bi0:bi1, bj0:bj1]].max()
    #end for ii

    if reduce > 2:
        #now we have to build up our image again
        #simplest repeating scaling up:

        #result = repeat(repeat(result, reduce, axis=0),\
        #                reduce,axis=1)
        #result.shape = (img.shape[0]*reduce, img.shape[1]*reduce)
        result = UpsizeImage(result, reduce)
    return result
#RollingBall

